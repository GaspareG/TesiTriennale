\chapter{Computation of subgraph similarity}

	In this chapter we present four different theoretical algorithm to compute subgraphs similarity as previously defined: an exhaustive enumeration, two similar randomized approach using the tools described in the previous chapter and a naive randomized approach.\\
	
	In the following algorithms, we will make use of parallel instruction, but we leave the specific programming choices and the comparison among the different approaches in the next chapter.
	
% \section{Calculation of indices}
\section{Indices calculation}

Now we illustrate the procedures to calculate the Jaccard and Bray-Curtis indices, as they are independent from the next algorithms we will present.\\

As previously seen, instead of iterate over all the strings in $\Sigma^{q}$ we can restrict to $\mathcal{L} \subseteq \Sigma^{q}$, the set of all possible $q$-grams found in the $q$-paths of $G$. 

An additional improvement can be made: if we want to calculate the similarity between two set $A, B \subset V$ ranging over $\mathcal{W} = \{ x \in \Sigma^{q} : x \in L(A) \text{ or } x \in L(B) \} \subseteq \Sigma^{q}$ it is enough, as we can easily see that for $x \in ( \Sigma^{q} \setminus \mathcal{W} )$ both $f_A[x]$ and $f_B[x]$ are equal to zero.\\

A last note, we can observe that in the Jaccard index we don't have to explicitly calculate $f_{A \cup B}[x]$ and its summary, as the value of $R = \Sigma_{x \in \mathcal{W}} f_{A \cup B}[x]$ can be easily calculate from $f_{A}[x] \text{ and } f_{B}[x]$.\\

\begin{algorithm}[h]
	\small
	\DontPrintSemicolon
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\Input{\ $\mathcal{W}$, $f_{A}[x]$, $f_{X}[x]$}
	\Output{\ $BC(A,B) = $ the similarity between $A$ and $B$ according to Bray-Curtis index}
	\BlankLine
	$num \gets 0$\;
	$den \gets 0$\;
	\ForEach{$x \in \mathcal{W}$}{
		$num \gets num + 2 \times \min( f_{A}[x], f_{B}[x] )$\;
		$dem \gets den + f_{A}[x] + f_{B}[x]$\;
	}
	$BC \gets \frac{num}{den}$\;
	\Return{$BC$}
	\caption{\textsc{Bray-Curtis}}
	\label{alg:bray-curtis}
\end{algorithm}

\begin{algorithm}[h]
	\small
	\DontPrintSemicolon
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\Input{\ $\mathcal{W}$, $f_{A}[x]$, $f_{X}[x]$, $R$}
	\Output{\ $FJ(A,B) = $ the similarity between $A$ and $B$ according to Jaccard index}
	\BlankLine
	$num \gets 0$\;
	\ForEach{$x \in \mathcal{W}$}{
		$num \gets num + \min( f_{A}[x], f_{B}[x] )$\;
	}
	$FJ \gets \frac{num}{R}$\;
	\Return{$FJ$}
	\caption{\textsc{Jaccard}}
	\label{alg:jaccard}
\end{algorithm}

Defined this procedures, in the next algorithms we focus only to compute the values of $\mathcal{W}$, $f_{A}[x]$, $f_{B}[x]$ and $R$.

\clearpage 

\section{Naive approach}

    \begin{algorithm}[h]
    
    \small
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \Input{\ $G = (V,E, L)$ undirected labeled graph}
    \Output{\ }
    
    \BlankLine
    
    
    %\textbf{parallel} \ForEach{$u \in V$}{
    %    \ForEach{$v \in N(u)$}{
    %        \ForEach{$\langle C, f \rangle \in M_{i-1,v}$ such that $\chi(u) \not \in C$}{
    %            $f' \gets M_{i,u}\left(C \cup \{\chi(u)\}\right)$\;
    %            $M_{i,u} \gets \langle C \cup \{\chi(u)\}, f' + f \rangle$\;
    %        }
    %    }
    %}   

    % \Return{$M$}
    %\setcounter{AlgoLine}{0}
    
    \caption{\textsc{brute-force}}
    
    \label{alg:brute-force}
    \end{algorithm}

	TODO 
\clearpage

\section{Efficient computation}

% \clearpage

\subsection*{Color coding}

TODO 
% \clearpage

\subsection*{Colorful sampling}

TODO 
% \clearpage

\subsection*{Frequency count}

TODO 
% \clearpage

\subsection*{Frequency sampling}

TODO 
% \clearpage

\subsection*{Estimating similarity indices}

TODO 
\clearpage

\section{Baseline algorithm}

In order to validate the effectiveness of our approach, we compare the previously seen algorithms against a naive randomized approach 

 the baseline algorithm BASELINE, 
that finds random paths in a simple way,

\begin{algorithm}[h]
	
	\small
	\DontPrintSemicolon
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\Input{\ $X =$ array of nodes from graph $G$; $ r =$ number of paths to sample.}
	\Output{\ $f_X[x] = $ frequency of each $x \in W$, where $W = $ naive random sample multiset of $q$-grams for $X$.}
	
	$R\gets\{\}$\;
	\textbf{parallel} \For{$j\in [r]$}{
		$u\gets$ randomly chosen $v \in X$ with uniform probability\;
		$P\gets \textsc{naive-random-path-to}(u)$\;
		\lIf{$P \neq \mathtt{null}$ and $P\not\in R$}{$R \gets R \cup \{ P \}$ \quad //critical section}
		\lElse{$j\gets j-1$ \quad //repeat the step}
	}
	$W \gets [ L(P) : P \in R ]$\;
	$f_X \gets (0,\ldots,0)$\;
	\lForEach{$x \in W$}{
		$f_X[x] \gets f_X[x]+1$
	}
	\Return{$f_X$}
	%\setcounter{AlgoLine}{0}
	
	\BlankLine
	
	\SetKwProg{myproc}{Function}{}{}
	\myproc{\textsc{naive-random-path-to}(u)}{
		$P\gets \langle u \rangle$\;
		\For{$i \in \{q-1,\ldots, 1\}$}{
			\lIf{$N(u) \setminus P = \emptyset$}{return $\mathtt{null}$}
			$u\gets$ randomly chosen $v \in N(u) \setminus P$ with uniform prob.\;
			$P\gets u \cdot P$\;
		}
		\Return{P}   
	}
	
	\caption{\textsc{base}\xspace, the baseline sampler}
	\label{alg:baseline}
\end{algorithm}

\clearpage
