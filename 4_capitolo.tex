%%%%%%%%%%%%%%%%%%%%%%

\chapter{Project development}
    
    To confirm the validity, both in terms of correctness and performance, of our algorithms we implemented all the procedures previously illustrated. 
    The most important parts of the code can found in appendix of this thesis.
    
    \section{Implementation choices and steps}
    
    The algorithms have been implemented using the C++ programming language, 
    as it provides good performance in practice and a lot of well-implemented data structures in the Standard Template Library.\\
    
    We first implements the $\textsc{brute}$ algorithm as it was the simpler and give us the correct answers, then we have implemented the three algorithms $\textsc{f-cont}$, $\textsc{f-samp}$, $\textsc{base}$ and check if some practical test give us some reasonable values.
    After making sure that all correctly work, we pass to parallelize them.\\
    
    The parallelization has been implemented using the OpenMP API, which defines a simple and flexible interface for developing parallel applications, in particular we use it to manage the parallel for-loops and the critical sections.\\
    
    To make the tests repeatable we used random generators with fixed seed, the subgraphs $A$ and $B$ were generated in three different ways: two random and independent subsets of $V$, two connected component (generated by choosing two random nodes and then expanding them through a $\textsc{DFS}$), two ego-networks.\\
    
    All the code was written in a modular and highly customizable ways in order
    to better test the various algorithms, in the results we explicitly shown the parameter used to execute the tests.
    
    \clearpage
    \section{Dataset}
    
    For the experiments we use two different kind of dataset, a small one so we can easily brute-force the real indices and compare the relative errors, and a big one in order to benchmark the performance of the different approach.
    
    \paragraph*{NetInf} This graph represents the flow of information on the web among blogs and news websites. The graph was computed by the \textit{NetInf} approach, as part of the \textit{SNAP} project~\cite{netinf}, by tracking cascades of information diffusion to reconstruct ``who copies who'' relationships.
    
    \begin{itemize}
    	\item $V$ is the set of blog or news website, $|V| = 854$.
    	\item $E$, each website is connected to those who frequently copy their content, $|E| = 3824$.
    	\item $\Sigma$ is the set of ranking class of websites ($0$ top $4\%$, $1$ next $15\%$, $2$ next $30\%$, $3$ last $51\%$), $|\Sigma| = 4$.
    	\item $L$, each website is labeled according to its importance, using Amazon's Alexa ranking.
    \end{itemize}

    % Each node represents a blog or news website, and a website is connected to those who frequently copy their content. The graph contains 854 nodes and 3824 edges. We labelled websites according to their importance, using Amazon's Alexa ranking~\cite{alexarank}: the labels correspond to respectively the websites ranked in the top $4\%$, the following $15\%$, the following $30\%$, and the remaining $51\%$ (i.e. $|\Sigma|=4$). 
    
    \textsl{Considered query:} compute the similarity of two websites $a$ and $b$ or two sets of websites.
    
    \paragraph*{IMDb} In this graph, taken from the \textit{Internet Movie Database} we have:
    
    \begin{itemize}
    	\item $V$ is the set of all movies in \textit{IMDb},  $|V| = 1\,060\,209$.
		\item $E$, two movies are connected if their casts share at least one actor, $|E| = 288\,008\,472$.
		\item $\Sigma$ is the set of movies genre, $|\Sigma| = 36$.
		\item $L$, each movie is labeled with its principal genre.
    \end{itemize}
    
    % , nodes correspond to movies, and there is a link between two movies if their casts share at least one actor. The graph contains 1\,060\,209 movies (nodes) and 288\,008\,472 edges. Each movie is labeled with one of $|\Sigma|=36$ genres. 
    
    \textsl{Considered query:} similarity of actors' ego-networks. Given two actors $a$ and $b$, let $A$ and $B$ be their ego-networks, i.e., the sets of nodes corresponding to movies in which respectively $a$ and $b$ starred, compute the similarity of $A$ and $B$.\\
    %Compute $BC(A,B)$, $J(A,B)$, $FJ(A,B)$, and random $q$-walks.
    
    The way we generate the $\textsc{IMDb}$ graph is an example of collaboration graph and is known in literature as Co-stardom network.
    
    \section{Experimental results}

    We describe the experimental evaluation for our approach. Our computing platform is a machine with Intel(R) Xeon(R) CPU E5-2620 v3 at 2.40GHz, 24 virtual cores, 128 Gb RAM, running Ubuntu Linux v.4.4.0-22-generic. Code written in C++17, compiled with g++ v.5.4.1 and OpenMP 4.5.\\
    
    To better analyze the different approaches described, we take several kinds of experiment in each of them .\footnote{Unless otherwise stated all the results are the average of $100$ identical experiment, in order to reduce the possible errors randomly caused by the machine.}\\
     
    An important fact of which to take into account is that we make large use of parallelization, 
    so all the running times scale (approximately) linearly on the number of cores used.
    
	\subsection*{Running time}
	
	In this experiment we compare the different running time, of all the parts, from all algorithms. Note that this is an important experiments, as in the real application time is crucial factor.\\

	First of all we test how much we can go up in \textsc{Brute-Force} with the value of $q$ and the sample size, as this is our bottleneck to analyze the relative errors for the approximated methods.\\ 
	
	\begin{table}[h]
		\centering
		\label{my-label}
		\begin{tabular}{|c|c|c|}
			\hline
			$q$ & $|A \cup B|$ & \textsc{Brute-Force} \\ \hline
			$4$ & $100$        & $1\,234$ \\ \hline
			$4$ & $200$        & $1\,234$ \\ \hline
			$4$ & $500$        & $1\,234$ \\ \hline
			$5$ & $100$        & $1\,234$ \\ \hline
			$5$ & $200$        & $1\,234$ \\ \hline
			$5$ & $500$        & $1\,234$ \\ \hline
			$6$ & $100$        & $1\,234$ \\ \hline
			$6$ & $200$        & $1\,234$ \\ \hline
			$6$ & $500$        & $1\,234$ \\ \hline
		\end{tabular}
		\caption{Time in milliseconds}
	\end{table}
	
	\clearpage
	
	The second bottleneck for our algorithms is the preprocessing time for the dynamic programming table of color-coding, so we test for both the dataset how can we go up with the value of $q$. Always remembering from initial assumptions that the value of $q$ should not be to high. 

	\begin{table}[h]
		\centering
		\label{my-label}
		\begin{tabular}{|c|c|c|}
			\hline
			$Dataset$       & $q$  & \textsc{Color-Coding} \\ \hline
			\textsc{NetInf} & $7$  & $1\,234$ \\ \hline
			\textsc{NetInf} & $9$  & $1\,234$ \\ \hline
			\textsc{NetInf} & $11$ & $1\,234$ \\ \hline
			\textsc{NetInf} & $13$ & $1\,234$ \\ \hline
			\textsc{NetInf} & $15$ & $1\,234$ \\ \hline
			\textsc{IMDb}   & $3$  & $1\,234$ \\ \hline
			\textsc{IMDb}   & $4$  & $1\,234$ \\ \hline
			\textsc{IMDb}   & $5$  & $1\,234$ \\ \hline
			\textsc{IMDb}   & $6$  & $1\,234$ \\ \hline
		\end{tabular}
		\caption{Time in milliseconds}
	\end{table}

	We can observe that, even in \textsc{IMDb} dataset, the value of $q$ could go high as we expected. To better understand these values, the official \textsc{IMDb} statistic told us that, out of $1\,837\,357$ actors analyzed, $1\,579\,193$ ($\sim86\%$) are distant $q=3$ from the actor \textit{Kevin Bacon} and $1\,795\,352$ ($\sim98\%$) are distant $q=6$.\\
	
	Finally we test the running time for the different approaches for different value of $q$ and number $R$ of $q$-paths sampled.
	
	\begin{table}[h]
		\centering
		\label{my-label}
		\begin{tabular}{|c|c|c|c|c|c|c|c|}
			\hline
			$Dataset$       & $q$  & $|A|$ & $|B|$ & $R$ & \textsc{F-Count} & \textsc{F-Sample} & \textsc{Base} \\ \hline
			\textsc{NetInf} & $7$  & $100$ & $100$ & $1\,000$ & $1\,000$ & $1\,000$ & $1\,000$ \\ \hline
			\textsc{NetInf} & $7$  & $100$ & $100$ & $1\,000$ & $1\,000$ & $1\,000$ & $1\,000$ \\ \hline
			\textsc{NetInf} & $7$  & $100$ & $100$ & $1\,000$ & $1\,000$ & $1\,000$ & $1\,000$ \\ \hline
			\textsc{NetInf} & $7$  & $100$ & $100$ & $1\,000$ & $1\,000$ & $1\,000$ & $1\,000$ \\ \hline
			\textsc{NetInf} & $7$  & $100$ & $100$ & $1\,000$ & $1\,000$ & $1\,000$ & $1\,000$ \\ \hline
			\textsc{NetInf} & $7$  & $100$ & $100$ & $1\,000$ & $1\,000$ & $1\,000$ & $1\,000$ \\ \hline
			\textsc{IMDb}   & $3$  & $100$ & $100$ & $1\,000$ & $1\,000$ & $1\,000$ & $1\,000$ \\ \hline
			\textsc{IMDb}   & $3$  & $100$ & $100$ & $1\,000$ & $1\,000$ & $1\,000$ & $1\,000$ \\ \hline
			\textsc{IMDb}   & $3$  & $100$ & $100$ & $1\,000$ & $1\,000$ & $1\,000$ & $1\,000$ \\ \hline
			\textsc{IMDb}   & $3$  & $100$ & $100$ & $1\,000$ & $1\,000$ & $1\,000$ & $1\,000$ \\ \hline
			
		\end{tabular}
		\caption{Time in milliseconds}
	\end{table}
	
	
	
	\subsection*{Relative error and variance}
	
%	In this experiment we will compare, for increasing value of $R$, how accurate are the different algorithms.\\
		
	TODO
	\begin{table}[h]
		\centering
		\label{my-label}
		\begin{tabular}{|c|c|c|c|}
			\hline
			Dataset 		& $q$ & \textsc{Color-Coding} 	& \textsc{BruteForce} \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $4$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $5$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $6$ & $1234$					& $1234$ \\ \hline
		\end{tabular}
		\caption{Time in milliseconds}
	\end{table}
		
	\subsection*{Fixed relative error}
	
	In this experiment we set the relative error $\epsilon_{r}$ and compare how many paths $R$ we need to reach such relative error.\\
	
	TODO
	\begin{table}[h]
		\centering
		\label{my-label}
		\begin{tabular}{|c|c|c|c|}
			\hline
			Dataset 		& $q$ & \textsc{Color-Coding} 	& \textsc{BruteForce} \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $4$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $5$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $6$ & $1234$					& $1234$ \\ \hline
		\end{tabular}
		\caption{Time in milliseconds}
	\end{table}
	
	\subsection*{Fixed time precision}
	
	In this experiment we set the computing time and compare how many path.\\
	
	TODO
	\begin{table}[h]
		\centering
		\label{my-label}
		\begin{tabular}{|c|c|c|c|}
			\hline
			Dataset 		& $q$ & \textsc{Color-Coding} 	& \textsc{BruteForce} \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{NetInf}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $3$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $4$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $5$ & $1234$					& $1234$ \\ \hline
			\textsc{IMDb}	& $6$ & $1234$					& $1234$ \\ \hline
		\end{tabular}
		\caption{Time in milliseconds}
	\end{table}

	\subsection*{Actors' ego-networks}
	
	As last test, in order to show a real application easy to understand, we compare
	some pairs of actors' ego-networks (using \fcount algorithm with $q=3$ and $R=1\,000$):
	
	\begin{table}[h]
		\centering
		\begin{tabular}{c|c|l|l}
			Actor/actress & Actor/actress & BC index & FJ index\\ 
			\hline
			Stan Laurel & Oliver Hardy & 0.936167 & 0.774053 \\
			Robert De Niro & Al Pacino & 0.730935 & 0.231474\\
			Woody Allen & Meryl Streep & 0.556071 & 0.222857\\
			Meryl Streep & Roberto Benigni & 0.482909 & 0.160181\\
			%\hline
		\end{tabular}
	\end{table}

	The values respect the theory very faithfully for many reasons.
	
	The Bray-Curtis index, as we already told, is always greater than the Frequency Jaccard and takes more into account the intersection:
	the ego-networks of the famous comic duo Laurel and Hardy have a big intersection, this make the Bray-Curtis value very close to 1, however the Frequency-Jaccard is much smaller as Oliver Hardy starred in about $300$ movie without Stan Laurel.
	
	One last observation about the couple Meryl Streep and Roberto Benigni: we have a big difference between the Bray-Curtis and the Frequency Jaccard, this can be due from the fact they are both famous actors (both won the Oscar Prize) who starred with a lot of other famous actor but they haven't starred together.